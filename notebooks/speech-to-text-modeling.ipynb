{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will import helper modelues for modeling and train speech-to-text models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 21:18:54.280190: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-09 21:18:54.280229: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "# Custom scripts\n",
    "from scripts.generate_amharic_characters import GenerateCharacters\n",
    "from scripts.metadata_loader import MetaDataLoader\n",
    "from scripts.audio_generator import make_audio_gen\n",
    "from scripts.model_arch import model_1, train\n",
    "\n",
    "char_gen = GenerateCharacters()\n",
    "md_loader = MetaDataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "amharic_root = \"../data/AMHARIC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus_path = f\"{amharic_root}/transcriptions_amharic.csv\"\n",
    "characters = char_gen.get_characters(md_path=train_corpus_path)\n",
    "characters = sorted(characters)\n",
    "characters = characters[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_map = {}\n",
    "char_map[\"\"] = 0\n",
    "char_map[\"<SPACE>\"] = 1\n",
    "index = 2\n",
    "for c in characters:\n",
    "    char_map[c] = index\n",
    "    index += 1\n",
    "index_map = {v+1: k for k, v in char_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8700\n",
      "2175\n"
     ]
    }
   ],
   "source": [
    "TRAIN_CORPUS = os.path.join(amharic_root, \"train_corpus.json\")\n",
    "VALID_CORPUS = os.path.join(amharic_root, \"valid_corpus.json\")\n",
    "\n",
    "MFCC_DIM = 13\n",
    "SPECTOGRAM = True\n",
    "EPOCHS = 1\n",
    "MODEL_NAME = \"RNN_model\"\n",
    "\n",
    "\n",
    "MINI_BATCH_SIZE = 64\n",
    "\n",
    "SORT_BY_DURATION=False\n",
    "MAX_DURATION = 10.0\n",
    "\n",
    "audio_gen = make_audio_gen(TRAIN_CORPUS, \n",
    "                        VALID_CORPUS, \n",
    "                        spectrogram=False, \n",
    "                        mfcc_dim=MFCC_DIM,\n",
    "                        minibatch_size=MINI_BATCH_SIZE, \n",
    "                        sort_by_duration=SORT_BY_DURATION,\n",
    "                        max_duration=MAX_DURATION, \n",
    "                        char_map=char_map)\n",
    "# add the training data to the generator\n",
    "audio_gen.load_train_data()\n",
    "audio_gen.load_validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " the_input (InputLayer)      [(None, None, 13)]        0         \n",
      "                                                                 \n",
      " rnn (GRU)                   (None, None, 5)           300       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, None, 5)          20        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, None, 224)        1344      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " softmax (Activation)        (None, None, 224)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,664\n",
      "Trainable params: 1,654\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-09 21:19:00.918004: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-06-09 21:19:00.918054: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-60-46.ec2.internal): /proc/driver/nvidia/version does not exist\n",
      "2022-06-09 21:19:00.918739: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = model_1(input_dim=MFCC_DIM,\n",
    "                units=5,\n",
    "                activation='relu',\n",
    "                output_dim=len(char_map)+1,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../scripts/model_arch.py:93: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  callbacks=[checkpointer], verbose=verbose, use_multiprocessing=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 147s 1s/step - loss: nan - val_loss: nan\n",
      "{'loss': [nan], 'val_loss': [nan]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train(audio_gen, \n",
    "    input_to_softmax=model, \n",
    "    model_name=MODEL_NAME, \n",
    "    epochs=EPOCHS, \n",
    "    minibatch_size=MINI_BATCH_SIZE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d48d82178da3f1670aabbf5b415675f34af166575db11104a58b14cda505a339"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
