{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stella_DeepLearningAmharic.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Deep learning Model implementation"
      ],
      "metadata": {
        "id": "uxqooBXjug4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Importing all necessary libraries"
      ],
      "metadata": {
        "id": "IcvRdxepvm1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "ifq33dDw3fji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Network\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "from keras import regularizers, callbacks\n",
        "from keras.constraints import max_norm\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import Input, Lambda, Dense, Dropout, Flatten, Embedding, Activation, GRUCell, LSTMCell,SimpleRNNCell\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Convolution1D, Conv1D, SimpleRNN, GRU, LSTM, CuDNNLSTM, CuDNNGRU, Conv2D\n",
        "from keras.layers import LeakyReLU, PReLU, ThresholdedReLU, ELU\n",
        "from keras.layers import BatchNormalization, TimeDistributed, Bidirectional\n",
        "from keras.layers import Wrapper\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta, Adamax, Nadam\n",
        "from keras.callbacks import ModelCheckpoint \n",
        "from keras.utils import np_utils\n",
        "from keras import constraints, initializers, regularizers\n",
        "import keras.losses\n"
      ],
      "metadata": {
        "id": "uL-Mb7utuw2X"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Importing helper scripts to google collab"
      ],
      "metadata": {
        "id": "D_r2XI_4wmPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "PEc_W831vkqW",
        "outputId": "688c9324-8e1c-46aa-d6fc-6a50d8699cce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d0cf8ef3-e76f-40c3-880a-9d56edff0463\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d0cf8ef3-e76f-40c3-880a-9d56edff0463\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving AudioGenerator.py to AudioGenerator.py\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AudioGenerator.py': b'import tensorflow as tf\\r\\nimport keras.losses\\r\\nfrom keras import constraints, initializers, regularizers\\r\\nfrom keras.utils import np_utils\\r\\nfrom keras.callbacks import ModelCheckpoint\\r\\nfrom keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta, Adamax, Nadam\\r\\nfrom keras.regularizers import l2\\r\\nfrom keras.layers import Wrapper\\r\\nfrom keras.layers import BatchNormalization, TimeDistributed, Bidirectional\\r\\nfrom keras.layers import LeakyReLU, PReLU, ThresholdedReLU, ELU\\r\\nfrom keras.layers import (\\r\\n    Convolution2D,\\r\\n    MaxPooling2D,\\r\\n    Convolution1D,\\r\\n    Conv1D,\\r\\n    SimpleRNN,\\r\\n    GRU,\\r\\n    LSTM,\\r\\n    CuDNNLSTM,\\r\\n    CuDNNGRU,\\r\\n    Conv2D,\\r\\n)\\r\\nfrom keras.layers import (\\r\\n    Input,\\r\\n    Lambda,\\r\\n    Dense,\\r\\n    Dropout,\\r\\n    Flatten,\\r\\n    Embedding,\\r\\n    Activation,\\r\\n    GRUCell,\\r\\n    LSTMCell,\\r\\n    SimpleRNNCell,\\r\\n)\\r\\nfrom keras.models import Model, Sequential, load_model\\r\\nfrom keras.constraints import max_norm\\r\\nfrom keras import regularizers, callbacks\\r\\nfrom keras import backend as K\\r\\nfrom keras.utils.generic_utils import get_custom_objects\\r\\nimport keras\\r\\nfrom scipy.fftpack import fft\\r\\nimport scipy.io.wavfile as wav\\r\\nfrom python_speech_features import mfcc\\r\\nfrom scipy.fftpack import dct\\r\\nfrom scipy import signal\\r\\nimport json\\r\\nimport soundfile\\r\\nfrom numpy.lib.stride_tricks import as_strided\\r\\nfrom random import sample\\r\\nimport random\\r\\nimport pickle\\r\\nimport sys\\r\\nimport os\\r\\nimport pandas as pd\\r\\nimport numpy as np\\r\\nfrom prep import prep\\r\\n\\r\\nprep = prep()\\r\\n# Audio processing\\r\\n# Neural Network\\r\\n\\r\\n# Setting Random Seeds\\r\\nnp.random.seed(95)\\r\\nRNG_SEED = 95\\r\\n\\r\\n\\r\\nclass AudioGenerator:\\r\\n    def __init__(\\r\\n        self,\\r\\n        step=10,\\r\\n        window=20,\\r\\n        max_freq=8000,\\r\\n        mfcc_dim=13,\\r\\n        minibatch_size=20,\\r\\n        desc_file=None,\\r\\n        spectrogram=True,\\r\\n        max_duration=10.0,\\r\\n        sort_by_duration=False,\\r\\n    ):\\r\\n        # Initializing variables\\r\\n        self.feat_dim = prep.calc_feat_dim(window, max_freq)\\r\\n        self.mfcc_dim = mfcc_dim\\r\\n        self.feats_mean = np.zeros((self.feat_dim,))\\r\\n        self.feats_std = np.ones((self.feat_dim,))\\r\\n        self.rng = random.Random(RNG_SEED)\\r\\n        if desc_file is not None:\\r\\n            self.load_metadata_from_desc_file(desc_file)\\r\\n        self.step = step\\r\\n        self.window = window\\r\\n        self.max_freq = max_freq\\r\\n        self.cur_train_index = 0\\r\\n        self.cur_valid_index = 0\\r\\n        self.cur_test_index = 0\\r\\n        self.max_duration = max_duration\\r\\n        self.minibatch_size = minibatch_size\\r\\n        self.spectrogram = spectrogram\\r\\n        self.sort_by_duration = sort_by_duration\\r\\n\\r\\n    def get_batch(self, partition):\\r\\n        # Obtain a batch of audio files\\r\\n        if partition == \"train\":\\r\\n            audio_paths = self.train_audio_paths\\r\\n            cur_index = self.cur_train_index\\r\\n            texts = self.train_texts\\r\\n        elif partition == \"valid\":\\r\\n            audio_paths = self.valid_audio_paths\\r\\n            cur_index = self.cur_valid_index\\r\\n            texts = self.valid_texts\\r\\n        elif partition == \"test\":\\r\\n            audio_paths = self.test_audio_paths\\r\\n            cur_index = self.test_valid_index\\r\\n            texts = self.test_texts\\r\\n        else:\\r\\n            raise Exception(\"Invalid partition. Must be train/validation/test\")\\r\\n\\r\\n        features = [\\r\\n            self.normalize(self.featurize(a))\\r\\n            for a in audio_paths[cur_index : cur_index + self.minibatch_size]\\r\\n        ]\\r\\n\\r\\n        # Calculate size\\r\\n        max_length = max([features[i].shape[0] for i in range(0, self.minibatch_size)])\\r\\n        max_string_length = max(\\r\\n            [len(texts[cur_index + i]) for i in range(0, self.minibatch_size)]\\r\\n        )\\r\\n\\r\\n        # Initialize arrays\\r\\n        X_data = np.zeros(\\r\\n            [\\r\\n                self.minibatch_size,\\r\\n                max_length,\\r\\n                self.feat_dim * self.spectrogram\\r\\n                + self.mfcc_dim * (not self.spectrogram),\\r\\n            ]\\r\\n        )\\r\\n        labels = np.ones([self.minibatch_size, max_string_length]) * 28\\r\\n        input_length = np.zeros([self.minibatch_size, 1])\\r\\n        label_length = np.zeros([self.minibatch_size, 1])\\r\\n\\r\\n        for i in range(0, self.minibatch_size):\\r\\n            # Calculate input_length\\r\\n            feat = features[i]\\r\\n            input_length[i] = feat.shape[0]\\r\\n            X_data[i, : feat.shape[0], :] = feat\\r\\n\\r\\n            # Calculate label_length\\r\\n            label = np.array(prep.text_to_int_seq(texts[cur_index + i]))\\r\\n            labels[i, : len(label)] = label\\r\\n            label_length[i] = len(label)\\r\\n\\r\\n        # Output arrays\\r\\n        outputs = {\"ctc\": np.zeros([self.minibatch_size])}\\r\\n        inputs = {\\r\\n            \"the_input\": X_data,\\r\\n            \"the_labels\": labels,\\r\\n            \"input_length\": input_length,\\r\\n            \"label_length\": label_length,\\r\\n        }\\r\\n        return (inputs, outputs)\\r\\n\\r\\n    def shuffle_dataset_by_partition(self, partition):\\r\\n        # More shuffling\\r\\n        if partition == \"train\":\\r\\n            (\\r\\n                self.train_audio_paths,\\r\\n                self.train_durations,\\r\\n                self.train_texts,\\r\\n            ) = prep.shuffle_dataset(\\r\\n                self.train_audio_paths, self.train_durations, self.train_texts\\r\\n            )\\r\\n        elif partition == \"valid\":\\r\\n            (\\r\\n                self.valid_audio_paths,\\r\\n                self.valid_durations,\\r\\n                self.valid_texts,\\r\\n            ) = prep.shuffle_dataset(\\r\\n                self.valid_audio_paths, self.valid_durations, self.valid_texts\\r\\n            )\\r\\n        else:\\r\\n            raise Exception(\"Invalid partition. \" \"Must be train/val\")\\r\\n\\r\\n    def sort_dataset_by_duration(self, partition):\\r\\n        # Extra shuffling\\r\\n        if partition == \"train\":\\r\\n            (\\r\\n                self.train_audio_paths,\\r\\n                self.train_durations,\\r\\n                self.train_texts,\\r\\n            ) = prep.sort_dataset(\\r\\n                self.train_audio_paths, self.train_durations, self.train_texts\\r\\n            )\\r\\n        elif partition == \"valid\":\\r\\n            (\\r\\n                self.valid_audio_paths,\\r\\n                self.valid_durations,\\r\\n                self.valid_texts,\\r\\n            ) = prep.sort_dataset(\\r\\n                self.valid_audio_paths, self.valid_durations, self.valid_texts\\r\\n            )\\r\\n        else:\\r\\n            raise Exception(\"Invalid partition. \" \"Must be train/val\")\\r\\n\\r\\n    def next_train(self):\\r\\n        # Get a batch of training data\\r\\n        while True:\\r\\n            ret = self.get_batch(\"train\")\\r\\n            self.cur_train_index += self.minibatch_size\\r\\n            if self.cur_train_index >= len(self.train_texts) - self.minibatch_size:\\r\\n                self.cur_train_index = 0\\r\\n                self.shuffle_dataset_by_partition(\"train\")\\r\\n            yield ret\\r\\n\\r\\n    def next_valid(self):\\r\\n        # Get a batch of validation data\\r\\n        while True:\\r\\n            ret = self.get_batch(\"valid\")\\r\\n            self.cur_valid_index += self.minibatch_size\\r\\n            if self.cur_valid_index >= len(self.valid_texts) - self.minibatch_size:\\r\\n                self.cur_valid_index = 0\\r\\n                self.shuffle_dataset_by_partition(\"valid\")\\r\\n            yield ret\\r\\n\\r\\n    def next_test(self):\\r\\n        # Get a batch of testing data\\r\\n        while True:\\r\\n            ret = self.get_batch(\"test\")\\r\\n            self.cur_test_index += self.minibatch_size\\r\\n            if self.cur_test_index >= len(self.test_texts) - self.minibatch_size:\\r\\n                self.cur_test_index = 0\\r\\n            yield ret\\r\\n\\r\\n    # Load datasets\\r\\n    def load_train_data(self, desc_file=\"../data/train_corpus.json\"):\\r\\n        self.load_metadata_from_desc_file(desc_file, \"train\")\\r\\n        self.fit_train()\\r\\n        if self.sort_by_duration:\\r\\n            self.sort_dataset_by_duration(\"train\")\\r\\n\\r\\n    def load_validation_data(self, desc_file=\"../data/valid_corpus.json\"):\\r\\n        self.load_metadata_from_desc_file(desc_file, \"validation\")\\r\\n        if self.sort_by_duration:\\r\\n            self.sort_dataset_by_duration(\"valid\")\\r\\n\\r\\n    def load_test_data(self, desc_file=\"../data/test_corpus.json\"):\\r\\n        self.load_metadata_from_desc_file(desc_file, \"test\")\\r\\n        if self.sort_by_duration:\\r\\n            self.sort_dataset_by_duration(\"test\")\\r\\n\\r\\n    def load_metadata_from_desc_file(self, desc_file, partition):\\r\\n        # Get metadata from json corpus\\r\\n        audio_paths, durations, texts = [], [], []\\r\\n        with open(desc_file) as json_line_file:\\r\\n            for line_num, json_line in enumerate(json_line_file):\\r\\n                try:\\r\\n                    spec = json.loads(json_line)\\r\\n                    if float(spec[\"duration\"]) > self.max_duration:\\r\\n                        continue\\r\\n                    audio_paths.append(spec[\"key\"])\\r\\n                    durations.append(float(spec[\"duration\"]))\\r\\n                    texts.append(spec[\"text\"])\\r\\n                except Exception as e:\\r\\n                    print(\"Error reading line #{}: {}\".format(line_num, json_line))\\r\\n        if partition == \"train\":\\r\\n            self.train_audio_paths = audio_paths\\r\\n            self.train_durations = durations\\r\\n            self.train_texts = texts\\r\\n        elif partition == \"validation\":\\r\\n            self.valid_audio_paths = audio_paths\\r\\n            self.valid_durations = durations\\r\\n            self.valid_texts = texts\\r\\n        elif partition == \"test\":\\r\\n            self.test_audio_paths = audio_paths\\r\\n            self.test_durations = durations\\r\\n            self.test_texts = texts\\r\\n        else:\\r\\n            raise Exception(\"Invalid partition. \" \"Must be train/validation/test\")\\r\\n\\r\\n    def fit_train(self, k_samples=100):\\r\\n        # Estimate descriptive stats for training set based on sample of 100 instances\\r\\n        k_samples = min(k_samples, len(self.train_audio_paths))\\r\\n        samples = self.rng.sample(self.train_audio_paths, k_samples)\\r\\n        feats = [self.featurize(s) for s in samples]\\r\\n        feats = np.vstack(feats)\\r\\n        self.feats_mean = np.mean(feats, axis=0)\\r\\n        self.feats_std = np.std(feats, axis=0)\\r\\n\\r\\n    # Defining 3 different ways of converting audio files to spectrograms\\r\\n\\r\\n    def spectrogramm(self, samples, fft_length=256, sample_rate=2, hop_length=128):\\r\\n        # Create a spectrogram from audio signals\\r\\n        assert not np.iscomplexobj(samples), \"You shall not pass in complex numbers\"\\r\\n        window = np.hanning(fft_length)[:, None]\\r\\n        window_norm = np.sum(window**2)\\r\\n        scale = window_norm * sample_rate\\r\\n        trunc = (len(samples) - fft_length) % hop_length\\r\\n        x = samples[: len(samples) - trunc]\\r\\n        # Reshape to include the overlap\\r\\n        nshape = (fft_length, (len(x) - fft_length) // hop_length + 1)\\r\\n        nstrides = (x.strides[0], x.strides[0] * hop_length)\\r\\n        x = as_strided(x, shape=nshape, strides=nstrides)\\r\\n        # Window stride sanity check\\r\\n        assert np.all(x[:, 1] == samples[hop_length : (hop_length + fft_length)])\\r\\n        # Broadcast window, and then compute fft over columns and square mod\\r\\n        x = np.fft.rfft(x * window, axis=0)\\r\\n        x = np.absolute(x) ** 2\\r\\n        # Scale 2.0 for everything except dc and fft_length/2\\r\\n        x[1:-1, :] *= 2.0 / scale\\r\\n        x[(0, -1), :] /= scale\\r\\n        freqs = float(sample_rate) / fft_length * np.arange(x.shape[0])\\r\\n        return x, freqs\\r\\n\\r\\n    def spectrogram_from_file(\\r\\n        self, filename, step=10, window=20, max_freq=None, eps=1e-14\\r\\n    ):\\r\\n        # Calculate log(linear spectrogram) from FFT energy\\r\\n        with soundfile.SoundFile(filename) as sound_file:\\r\\n            audio = sound_file.read(dtype=\"float32\")\\r\\n            sample_rate = sound_file.samplerate\\r\\n            if audio.ndim >= 2:\\r\\n                audio = np.mean(audio, 1)\\r\\n            if max_freq is None:\\r\\n                max_freq = sample_rate / 2\\r\\n            if max_freq > sample_rate / 2:\\r\\n                raise ValueError(\"max_freq can not be > than 0.5 of \" \" sample rate\")\\r\\n            if step > window:\\r\\n                raise ValueError(\"step size can not be > than window size\")\\r\\n            hop_length = int(0.001 * step * sample_rate)\\r\\n            fft_length = int(0.001 * window * sample_rate)\\r\\n            pxx, freqs = self.spectrogramm(\\r\\n                audio,\\r\\n                fft_length=fft_length,\\r\\n                sample_rate=sample_rate,\\r\\n                hop_length=hop_length,\\r\\n            )\\r\\n            ind = np.where(freqs <= max_freq)[0][-1] + 1\\r\\n        return np.transpose(np.log(pxx[:ind, :] + eps))\\r\\n\\r\\n    def log_spectrogram_feature(\\r\\n        self, samples, sample_rate, window_size=20, step_size=10, eps=1e-14\\r\\n    ):\\r\\n        nperseg = int(round(window_size * sample_rate / 1e3))\\r\\n        noverlap = int(round(step_size * sample_rate / 1e3))\\r\\n        freqs, times, spec = signal.spectrogram(\\r\\n            samples,\\r\\n            fs=sample_rate,\\r\\n            window=\"hann\",\\r\\n            nperseg=nperseg,\\r\\n            noverlap=noverlap,\\r\\n            detrend=False,\\r\\n        )\\r\\n        freqs = freqs * 2\\r\\n        return freqs, times, np.log(spec.T.astype(np.float64) + eps)\\r\\n\\r\\n    def featurize(self, audio_clip):\\r\\n        # Create features from data, either spectrogram or mfcc\\r\\n        if self.spectrogram:\\r\\n            return self.spectrogram_from_file(\\r\\n                audio_clip, step=self.step, window=self.window, max_freq=self.max_freq\\r\\n            )\\r\\n        else:\\r\\n            (rate, sig) = wav.read(audio_clip)\\r\\n            return mfcc(sig, rate, numcep=self.mfcc_dim)\\r\\n\\r\\n    def normalize(self, feature, eps=1e-14):\\r\\n        # Scale the data to improve neural network performance and reduce the size of the gradients\\r\\n        return (feature - self.feats_mean) / (self.feats_std + eps)\\r\\n\\r\\n    # Custom CTC loss function (discussed below)\\r\\n    def ctc_lambda_func(self, args):\\r\\n        y_pred, labels, input_length, label_length = args\\r\\n        return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\\r\\n\\r\\n    def add_ctc_loss(self, input_to_softmax):\\r\\n        the_labels = Input(name=\"the_labels\", shape=(None,), dtype=\"float32\")\\r\\n        input_lengths = Input(name=\"input_length\", shape=(1,), dtype=\"int64\")\\r\\n        label_lengths = Input(name=\"label_length\", shape=(1,), dtype=\"int64\")\\r\\n        output_lengths = Lambda(input_to_softmax.output_length)(input_lengths)\\r\\n        # CTC loss is implemented in a lambda layer\\r\\n        loss_out = Lambda(self.ctc_lambda_func, output_shape=(1,), name=\"ctc\")(\\r\\n            [input_to_softmax.output, the_labels, output_lengths, label_lengths]\\r\\n        )\\r\\n        model = Model(\\r\\n            inputs=[input_to_softmax.input, the_labels, input_lengths, label_lengths],\\r\\n            outputs=loss_out,\\r\\n        )\\r\\n        return model\\r\\n\\r\\n    # Function for modifying CNN layers for sequence problems\\r\\n    def cnn_output_length(\\r\\n        self, input_length, filter_size, border_mode, stride, dilation=1\\r\\n    ):\\r\\n        # Compute the length of cnn output seq after 1D convolution across time\\r\\n        if input_length is None:\\r\\n            return None\\r\\n        assert border_mode in {\"same\", \"valid\", \"causal\"}\\r\\n        dilated_filter_size = filter_size + (filter_size - 1) * (dilation - 1)\\r\\n        if border_mode == \"same\":\\r\\n            output_length = input_length\\r\\n        elif border_mode == \"valid\":\\r\\n            output_length = input_length - dilated_filter_size + 1\\r\\n        elif border_mode == \"causal\":\\r\\n            output_length = input_length\\r\\n        return (output_length + stride - 1) // stride\\r\\n\\r\\n    def train_model(\\r\\n        self,\\r\\n        input_to_softmax,\\r\\n        pickle_path,\\r\\n        save_model_path,\\r\\n        train_json=\"../data/train_corpus.json\",\\r\\n        valid_json=\"../data/valid_corpus.json\",\\r\\n        minibatch_size=16,  # You will want to change this depending on the GPU you are training on\\r\\n        spectrogram=True,\\r\\n        mfcc_dim=13,\\r\\n        optimizer=Adam(\\r\\n            lr=0.0001,\\r\\n            beta_1=0.9,\\r\\n            beta_2=0.999,\\r\\n            epsilon=None,\\r\\n            decay=0.0,\\r\\n            amsgrad=False,\\r\\n            clipnorm=1,\\r\\n            clipvalue=0.5,\\r\\n        ),\\r\\n        epochs=30,  # You will want to change this depending on the model you are training and data you are using\\r\\n        verbose=1,\\r\\n        sort_by_duration=False,\\r\\n        max_duration=10.0,\\r\\n    ):\\r\\n\\r\\n        # Obtain batches of data\\r\\n        audio_gen = AudioGenerator(\\r\\n            minibatch_size=minibatch_size,\\r\\n            spectrogram=spectrogram,\\r\\n            mfcc_dim=mfcc_dim,\\r\\n            max_duration=max_duration,\\r\\n            sort_by_duration=sort_by_duration,\\r\\n        )\\r\\n        # Load the datasets\\r\\n        audio_gen.load_train_data(train_json)\\r\\n        audio_gen.load_validation_data(valid_json)\\r\\n        # Calculate steps per epoch\\r\\n        num_train_examples = len(audio_gen.train_audio_paths)\\r\\n        steps_per_epoch = num_train_examples // minibatch_size\\r\\n        # Calculate validation steps\\r\\n        num_valid_samples = len(audio_gen.valid_audio_paths)\\r\\n        validation_steps = num_valid_samples // minibatch_size\\r\\n        # Add custom CTC loss function to the nn\\r\\n        model = self.add_ctc_loss(input_to_softmax)\\r\\n        # Dummy lambda function for loss since CTC loss is implemented above\\r\\n        model.compile(loss={\"ctc\": lambda y_true, y_pred: y_pred}, optimizer=optimizer)\\r\\n        # Make  initial results/ directory for saving model pickles\\r\\n        if not os.path.exists(\"../model\"):\\r\\n            os.makedirs(\"../model\")\\r\\n        # Add callbacks\\r\\n        checkpointer = ModelCheckpoint(\\r\\n            filepath=\"../model/\" + save_model_path, verbose=0\\r\\n        )\\r\\n        terminator = callbacks.TerminateOnNaN()\\r\\n        time_machiner = callbacks.History()\\r\\n        logger = callbacks.CSVLogger(\"../logs/training.log\")\\r\\n        stopper = callbacks.EarlyStopping(\\r\\n            monitor=\"val_loss\", patience=2, verbose=1, mode=\"auto\"\\r\\n        )\\r\\n        reducer = callbacks.ReduceLROnPlateau(\\r\\n            monitor=\"val_loss\",\\r\\n            factor=0.1,\\r\\n            patience=10,\\r\\n            verbose=0,\\r\\n            mode=\"auto\",\\r\\n            min_delta=0.0001,\\r\\n            cooldown=0,\\r\\n            min_lr=0,\\r\\n        )\\r\\n        tensor_boarder = callbacks.TensorBoard(\\r\\n            log_dir=\"./logs\",\\r\\n            batch_size=16,\\r\\n            write_graph=True,\\r\\n            write_grads=True,\\r\\n            write_images=True,\\r\\n        )\\r\\n        # Fit/train model\\r\\n        hist = model.fit_generator(\\r\\n            generator=audio_gen.next_train(),\\r\\n            steps_per_epoch=steps_per_epoch,\\r\\n            epochs=epochs,\\r\\n            validation_data=audio_gen.next_valid(),\\r\\n            validation_steps=validation_steps,\\r\\n            callbacks=[\\r\\n                checkpointer,\\r\\n                terminator,\\r\\n                logger,\\r\\n                time_machiner,\\r\\n                tensor_boarder,\\r\\n                stopper,\\r\\n                reducer,\\r\\n            ],\\r\\n            verbose=verbose,\\r\\n        )\\r\\n        # Save model loss\\r\\n        with open(\"../model/\" + pickle_path, \"wb\") as f:\\r\\n            pickle.dump(hist.history, f)\\r\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "JRBmLDdj4w3E",
        "outputId": "0d4e21a2-51fe-4343-b299-9e549e8b9f4a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9e8cd969-0f8e-4c06-bf48-fbb17f4a6de6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9e8cd969-0f8e-4c06-bf48-fbb17f4a6de6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving prep.py to prep.py\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'prep.py': b'\\r\\nfrom log_help import App_Logger\\r\\nimport numpy as np\\r\\nimport pandas as pd\\r\\nimport os\\r\\nimport sys\\r\\n\\r\\nsys.path.insert(0, \\'../scripts/\\')\\r\\nsys.path.insert(0, \\'../logs/\\')\\r\\nsys.path.append(os.path.abspath(os.path.join(\\'..\\')))\\r\\n\\r\\napp_logger = App_Logger(\"../logs/prep.log\").get_app_logger()\\r\\n\\r\\n\\r\\nclass prep:\\r\\n\\r\\n    def __init__(self):\\r\\n        \\'\\'\\'\\r\\n        # init\\r\\n        # @param self\\r\\n        # return: None\\r\\n        # @exception: None\\r\\n        # @note: None\\r\\n        # @example: None     \\r\\n        \\'\\'\\'\\r\\n        self.logger = App_Logger(\\r\\n            \"../logs/prep.log\").get_app_logger()\\r\\n        # Mapping each character that could be spoken at each time step\\r\\n        self.char_map_str = \"\"\"\\r\\n                \\xe1\\x88\\x80 \\xe1\\x88\\x81 \\xe1\\x88\\x82 \\xe1\\x88\\x80 \\xe1\\x88\\x84 \\xe1\\x88\\x85 \\xe1\\x88\\x86\\r\\n                \\xe1\\x88\\x88 \\xe1\\x88\\x89 \\xe1\\x88\\x8a \\xe1\\x88\\x8b \\xe1\\x88\\x8c \\xe1\\x88\\x8d \\xe1\\x88\\x8e \\xe1\\x88\\x8f\\r\\n                \\xe1\\x88\\x98 \\xe1\\x88\\x99 \\xe1\\x88\\x9a \\xe1\\x88\\x9b \\xe1\\x88\\x9c \\xe1\\x88\\x9d \\xe1\\x88\\x9e \\xe1\\x88\\x9f\\r\\n                \\xe1\\x88\\xa8 \\xe1\\x88\\xa9 \\xe1\\x88\\xaa \\xe1\\x88\\xab \\xe1\\x88\\xac \\xe1\\x88\\xad \\xe1\\x88\\xae \\xe1\\x88\\xaf\\r\\n                \\xe1\\x88\\xb0 \\xe1\\x88\\xb1 \\xe1\\x88\\xb2 \\xe1\\x88\\xb3 \\xe1\\x88\\xb4 \\xe1\\x88\\xb5 \\xe1\\x88\\xb6 \\xe1\\x88\\xb7\\r\\n                \\xe1\\x88\\xb8 \\xe1\\x88\\xb9 \\xe1\\x88\\xba \\xe1\\x88\\xbb \\xe1\\x88\\xbc \\xe1\\x88\\xbd \\xe1\\x88\\xbe \\xe1\\x88\\xbf\\r\\n                \\xe1\\x89\\x80 \\xe1\\x89\\x81 \\xe1\\x89\\x82 \\xe1\\x89\\x83 \\xe1\\x89\\x84 \\xe1\\x89\\x85 \\xe1\\x89\\x86 \\xe1\\x89\\x8b\\r\\n                \\xe1\\x89\\xa0 \\xe1\\x89\\xa1 \\xe1\\x89\\xa2 \\xe1\\x89\\xa3 \\xe1\\x89\\xa4 \\xe1\\x89\\xa5 \\xe1\\x89\\xa6 \\xe1\\x89\\xa7\\r\\n                \\xe1\\x89\\xa8 \\xe1\\x89\\xa9 \\xe1\\x89\\xaa \\xe1\\x89\\xab \\xe1\\x89\\xac \\xe1\\x89\\xad \\xe1\\x89\\xae \\xe1\\x89\\xaf\\r\\n                \\xe1\\x89\\xb0 \\xe1\\x89\\xb1 \\xe1\\x89\\xb2 \\xe1\\x89\\xb3 \\xe1\\x89\\xb4 \\xe1\\x89\\xb5 \\xe1\\x89\\xb6 \\xe1\\x89\\xb7\\r\\n                \\xe1\\x89\\xb8 \\xe1\\x89\\xb9 \\xe1\\x89\\xba \\xe1\\x89\\xbb \\xe1\\x89\\xbc \\xe1\\x89\\xbd \\xe1\\x89\\xbe \\xe1\\x89\\xbf\\r\\n                \\xe1\\x8a\\x90 \\xe1\\x8a\\x91 \\xe1\\x8a\\x92 \\xe1\\x8a\\x93 \\xe1\\x8a\\x94 \\xe1\\x8a\\x95 \\xe1\\x8a\\x96 \\xe1\\x8a\\x97\\r\\n                \\xe1\\x8a\\x98 \\xe1\\x8a\\x99 \\xe1\\x8a\\x9a \\xe1\\x8a\\x9b \\xe1\\x8a\\x9c \\xe1\\x8a\\x9d \\xe1\\x8a\\x9e \\xe1\\x8a\\x9f\\r\\n                \\xe1\\x8a\\xa0 \\xe1\\x8a\\xa1 \\xe1\\x8a\\xa2 \\xe1\\x8a\\xa4 \\xe1\\x8a\\xa5 \\xe1\\x8a\\xa6 \\xe1\\x8a\\xa7\\r\\n                \\xe1\\x8a\\xa8 \\xe1\\x8a\\xa9 \\xe1\\x8a\\xaa \\xe1\\x8a\\xab \\xe1\\x8a\\xac \\xe1\\x8a\\xad \\xe1\\x8a\\xae \\xe1\\x8a\\xaf\\r\\n                \\xe1\\x8b\\x88 \\xe1\\x8b\\x89 \\xe1\\x8b\\x8a \\xe1\\x8b\\x8b \\xe1\\x8b\\x8c \\xe1\\x8b\\x8d \\xe1\\x8b\\x8e\\r\\n                \\xe1\\x8b\\x98 \\xe1\\x8b\\x99 \\xe1\\x8b\\x9a \\xe1\\x8b\\x9b \\xe1\\x8b\\x9c \\xe1\\x8b\\x9d \\xe1\\x8b\\x9e \\xe1\\x8b\\x9f\\r\\n                \\xe1\\x8b\\xa0 \\xe1\\x8b\\xa1 \\xe1\\x8b\\xa2 \\xe1\\x8b\\xa3 \\xe1\\x8b\\xa4 \\xe1\\x8b\\xa5 \\xe1\\x8b\\xa6 \\xe1\\x8b\\xa7\\r\\n                \\xe1\\x8b\\xa8 \\xe1\\x8b\\xa9 \\xe1\\x8b\\xaa \\xe1\\x8b\\xab \\xe1\\x8b\\xac \\xe1\\x8b\\xad \\xe1\\x8b\\xae\\r\\n                \\xe1\\x8b\\xb0 \\xe1\\x8b\\xb1 \\xe1\\x8b\\xb2 \\xe1\\x8b\\xb3 \\xe1\\x8b\\xb4 \\xe1\\x8b\\xb5 \\xe1\\x8b\\xb6 \\xe1\\x8b\\xb7\\r\\n                \\xe1\\x8c\\x80 \\xe1\\x8c\\x81 \\xe1\\x8c\\x82 \\xe1\\x8c\\x83 \\xe1\\x8c\\x84 \\xe1\\x8c\\x85 \\xe1\\x8c\\x86 \\xe1\\x8c\\x87\\r\\n                \\xe1\\x8c\\x88 \\xe1\\x8c\\x89 \\xe1\\x8c\\x8a \\xe1\\x8c\\x8b \\xe1\\x8c\\x8c \\xe1\\x8c\\x8d \\xe1\\x8c\\x90 \\xe1\\x8c\\x93 \\xe1\\x8c\\x94\\r\\n                \\xe1\\x8c\\xa0 \\xe1\\x8c\\xa1 \\xe1\\x8c\\xa2 \\xe1\\x8c\\xa3 \\xe1\\x8c\\xa4 \\xe1\\x8c\\xa5 \\xe1\\x8c\\xa6 \\xe1\\x8c\\xa7\\r\\n                \\xe1\\x8c\\xa8 \\xe1\\x8c\\xa9 \\xe1\\x8c\\xaa \\xe1\\x8c\\xab \\xe1\\x8c\\xac \\xe1\\x8c\\xad \\xe1\\x8c\\xae \\xe1\\x8c\\xaf\\r\\n                \\xe1\\x8c\\xb0 \\xe1\\x8c\\xb1 \\xe1\\x8c\\xb2 \\xe1\\x8c\\xb3 \\xe1\\x8c\\xb4 \\xe1\\x8c\\xb5 \\xe1\\x8c\\xb6 \\xe1\\x8c\\xb7\\r\\n                \\xe1\\x8d\\x80 \\xe1\\x8d\\x81 \\xe1\\x8d\\x82 \\xe1\\x8d\\x83 \\xe1\\x8d\\x84 \\xe1\\x8d\\x85 \\xe1\\x8d\\x86 \\xe1\\x8d\\x87\\r\\n                \\xe1\\x8d\\x88 \\xe1\\x8d\\x89 \\xe1\\x8d\\x8a \\xe1\\x8d\\x8b \\xe1\\x8d\\x8c \\xe1\\x8d\\x8d \\xe1\\x8d\\x8e \\xe1\\x8d\\x8f\\r\\n                \\xe1\\x8d\\x90 \\xe1\\x8d\\x91 \\xe1\\x8d\\x92 \\xe1\\x8d\\x93 \\xe1\\x8d\\x94 \\xe1\\x8d\\x95 \\xe1\\x8d\\x96\\r\\n                \"\"\".split()\\r\\n        self.char_map = {}\\r\\n        self.char_map[\"\\'\"] = 0\\r\\n        self.char_map[\\' \\'] = 1\\r\\n        index = 2\\r\\n        for c in self.char_map_str:\\r\\n            self.char_map[c] = index\\r\\n            index += 1\\r\\n        self.index_map = {v+1: k for k, v in self.char_map.items()}\\r\\n\\r\\n    # Function for shuffling data which is important as neural networks make multiple passes through the data\\r\\n    def shuffle_dataset(self, audio_paths, durations, texts):\\r\\n        \\'\\'\\'\\r\\n        #  \\r\\n        \\'\\'\\'\\r\\n        p = np.random.permutation(len(audio_paths))\\r\\n        audio_paths = [audio_paths[i] for i in p]\\r\\n        durations = [durations[i] for i in p]\\r\\n        texts = [texts[i] for i in p]\\r\\n        self.logger.info(f\"shuffling {audio_paths} file\")\\r\\n        return audio_paths, durations, texts\\r\\n\\r\\n    # Function for sorting data by duration\\r\\n    def sort_dataset(self, audio_paths, durations, texts):\\r\\n        \\'\\'\\'\\r\\n        # \\r\\n        \\'\\'\\'\\r\\n        p = np.argsort(durations).tolist()\\r\\n        audio_paths = [audio_paths[i] for i in p]\\r\\n        durations = [durations[i] for i in p]\\r\\n        texts = [texts[i] for i in p]\\r\\n        self.logger.info(f\"sorting {audio_paths} file\")\\r\\n        return audio_paths, durations, texts\\r\\n\\r\\n    # Function for converting text to an integer sequence\\r\\n    def text_to_int_seq(self, text):\\r\\n        int_sequence = []\\r\\n        for c in text:\\r\\n            if c == \\' \\':\\r\\n                ch = self.char_map[\\'\\xe1\\x8a\\xa7\\']\\r\\n            else:\\r\\n                ch = self.char_map[\\'\\xe1\\x8a\\xa0\\']\\r\\n            int_sequence.append(ch)\\r\\n            self.logger.info(f\"converting {c} to {ch}\")\\r\\n        return int_sequence\\r\\n\\r\\n    # Function for converting an integer sequence to text\\r\\n    def int_seq_to_text(self, int_sequence):\\r\\n        text = []\\r\\n        for c in int_sequence:\\r\\n            ch = self.index_map[\\'\\xe1\\x8a\\xa0\\']\\r\\n            text.append(ch)\\r\\n            self.logger.info(f\"converting {c} to {ch}\")\\r\\n        return text\\r\\n    # Function for calculating feature dimensions.\\r\\n\\r\\n    def calc_feat_dim(self, window, max_freq):\\r\\n        return int(0.001 * window * max_freq) + 1\\r\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "seKAZg80yLtL",
        "outputId": "55dcbeac-2e92-4b37-b54c-4429fa75b6d7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-70b5a797-194b-4e37-afe2-264fde264cc1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-70b5a797-194b-4e37-afe2-264fde264cc1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving create_desc_json.py to create_desc_json.py\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'create_desc_json.py': b'\"\"\"\\r\\nWhere speaker.trans.txt has in each line, file_key\\r\\n\"\"\"\\r\\n\\r\\nfrom __future__ import absolute_import, division, print_function\\r\\nfrom log_help import App_Logger\\r\\n\\r\\n\\r\\nimport argparse\\r\\nimport json\\r\\nimport os\\r\\nimport sys\\r\\nimport wave\\r\\nimport librosa\\r\\nimport json\\r\\nimport pandas as pd\\r\\nimport numpy as np\\r\\nsys.path.insert(0, \\'../scripts/\\')\\r\\nsys.path.insert(0, \\'../logs/\\')\\r\\nsys.path.append(os.path.abspath(os.path.join(\\'..\\')))\\r\\n\\r\\napp_logger = App_Logger(\"../logs/create_desc_json.log\").get_app_logger()\\r\\n\\r\\n\\r\\nclass create_desc_json:\\r\\n\\r\\n    def __init__(self):\\r\\n        \\'\\'\\'\\r\\n        # init\\r\\n        # @param self\\r\\n        # return: None\\r\\n        # @exception: None\\r\\n        # @note: None\\r\\n        # @example: None     \\r\\n        \\'\\'\\'\\r\\n        self.logger = App_Logger(\\r\\n            \"../logs/create_desc_json.log\").get_app_logger()\\r\\n\\r\\n    def translation_loader(self, filename):\\r\\n        \\'\\'\\'\\r\\n        # Load the transcriptions\\r\\n        # @param filename: the path of the transcriptions\\r\\n        # return: a dictionary of the transcriptions\\r\\n        \\'\\'\\'\\r\\n        name_to_text = {}\\r\\n        with open(filename, encoding=\"utf-8\")as f:\\r\\n            f.readline()\\r\\n            for line in f:\\r\\n                name = line.split(\"</s>\")[1]\\r\\n                name = name.replace(\\'(\\', \\'\\')\\r\\n                name = name.replace(\\')\\', \\'\\')\\r\\n                name = name.replace(\\'\\\\n\\', \\'\\')\\r\\n                name = name.replace(\\' \\', \\'\\')\\r\\n                text = line.split(\"</s>\")[0]\\r\\n                text = text.replace(\"<s>\", \"\")\\r\\n                name_to_text[name] = text\\r\\n                self.logger.info(f\"cleaning {filename} file\")\\r\\n            return name_to_text\\r\\n\\r\\n    def meta_data(self, trans, path):\\r\\n        \\'\\'\\'\\r\\n        # Extract the meta-data\\r\\n        # @param trans: clean transcription\\r\\n        # @param path: location for audio files\\r\\n        # return: lists of the meta data\\r\\n        \\'\\'\\'\\r\\n        target = []\\r\\n        features = []\\r\\n        filenames = []\\r\\n        duration_of_recordings = []\\r\\n        for k in trans:\\r\\n            filename = path+k + \".wav\"\\r\\n            filenames.append(filename)\\r\\n            audio, fs = librosa.load(filename, sr=None)\\r\\n            duration_of_recordings.append(float(len(audio)/fs))\\r\\n            lable = trans[k]\\r\\n            target.append(lable)\\r\\n            self.logger.info(\\r\\n                f\"Extract the meta-data from transcription {path}\")\\r\\n        return filenames, target, duration_of_recordings\\r\\n\\r\\n    def convert_to_json(self, data: pd.DataFrame, path: str):\\r\\n        \\'\\'\\'\\r\\n        # convert dataframe to json\\r\\n        # @param data: dataframe\\r\\n        # @param path: path to save json\\r\\n        # return: None\\r\\n        # @exception: None\\r\\n        \\'\\'\\'\\r\\n        try:\\r\\n            with open(path, \\'w\\') as out_file:\\r\\n                for i in range(len(data[\\'key\\'])):\\r\\n                    line = json.dumps({\\'key\\': data[\\'key\\'][i], \\'duration\\': data[\\'duration\\'][i],\\r\\n                                       \\'text\\': data[\\'text\\'][i]})\\r\\n                    out_file.write(line + \\'\\\\n\\')\\r\\n                    self.logger.info(\\r\\n                        f\"Convert the dataframe to json file {path}\")\\r\\n        except KeyError:\\r\\n            var = 0\\r\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Defining model 0"
      ],
      "metadata": {
        "id": "wJEMBnT1xNsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN "
      ],
      "metadata": {
        "id": "BDqNcmH6x5i2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regular_rnn_model(input_dim, output_dim=29):\n",
        "    # Input\n",
        "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
        "    # Recurrent layer\n",
        "    simp_rnn = GRU(output_dim, return_sequences=True, \n",
        "                 implementation=2, name='rnn')(input_data)\n",
        "    # Softmax Activation Layer\n",
        "    y_pred = Activation('softmax', name='softmax')(simp_rnn)\n",
        "    # Specifying the model\n",
        "    model = Model(inputs=input_data, outputs=y_pred)\n",
        "    model.output_length = lambda x: x\n",
        "    print(model.summary())\n",
        "    return model"
      ],
      "metadata": {
        "id": "vzy0aR5ExQkE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = regular_rnn_model(input_dim=161)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD4_062GxSf_",
        "outputId": "845059a6-feed-4196-b9c3-ac2ff8ed75d0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " the_input (InputLayer)      [(None, None, 161)]       0         \n",
            "                                                                 \n",
            " rnn (GRU)                   (None, None, 29)          16704     \n",
            "                                                                 \n",
            " softmax (Activation)        (None, None, 29)          0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,704\n",
            "Trainable params: 16,704\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.test.is_gpu_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwnHs2-w5Xnw",
        "outputId": "8521d7f7-6eca-469b-f43e-e78903ed140f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d8Ikg24J5gGN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}