{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stella_PreprocessingSwahili.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0vXS1_ej2n61"
      },
      "outputs": [],
      "source": [
        "import librosa  # for audio processing\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.io import wavfile  # for audio processing\n",
        "from numpy.lib.stride_tricks import as_strided\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from IPython.display import Audio\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from os.path import exists\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# from cleaner import CleanDataFrame"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Preprocessing steps:\n",
        "1. Load labels\n",
        "2. sample each audio at 44100Hz\n",
        "3. Convert mono to stereo\n",
        "4. Resize audios\n",
        "5. Generate a pandas dataframe\n",
        "6. save preprocessed audios and transcritions to a new folder\n",
        "6. Split the data to train and valid corpus\n",
        "7.  save train and valid corpus\n"
      ],
      "metadata": {
        "id": "YKx9l0cq2zqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining file Paths"
      ],
      "metadata": {
        "id": "SUSartVbPPSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_location = 'train/SWA/'\n",
        "train_wav_location = os.path.join('/content/drive/My Drive/SWAHILI/data/train/wav/','SWA/')\n",
        "train_changed_wav_location = os.path.join('/content/drive/My Drive/SWAHILI/data/train/wav/','changed_wav/')\n",
        "train_txt_location = (\"/content/drive/My Drive/SWAHILI/data/train/text.txt\")\n",
        "test_dataset_location = 'test/' \n",
        "lexicon_location = 'train/SWA/'"
      ],
      "metadata": {
        "id": "rZeFFgp9O6oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_sterio(audio: np.array) -> np.array:\n",
        "        if len(audio.shape) == 1:\n",
        "            sterio = np.stack([audio, audio], axis=1)\n",
        "            return sterio\n",
        "        return audio\n",
        "\n",
        "\n",
        "from scipy.io import wavfile\n",
        "\n",
        "def resize_audio(audio: np.array, size: int) -> np.array:\n",
        "        \"\"\"\n",
        "        This resizes all input audio to a fixed sample size.\n",
        "        It helps us to have a consistent data shape\n",
        "\n",
        "        Args:\n",
        "            audio: This is the audio sample as a numpy array\n",
        "        \"\"\"\n",
        "        resized = librosa.util.fix_length(audio, size, axis=0)\n",
        "        print(f\"Audio resized to {size} samples\")\n",
        "        return resized\n",
        "# changed = convert_to_sterio(samples)\n",
        "# changed.shape  \n",
        "# resized = resize_audio(changed,200000)\n",
        "# print(resized.shape)\n",
        "# print(resized.T.shape)\n",
        "# wavfile.write(os.path.join(train_changed_wav_location, 'trial.wav'), sample_rate, resized)\n",
        "# ipd.Audio(resized.T, rate=sample_rate)\n",
        "# # mfcc = librosa.feature.mfcc(y=changed, sr=sample_rate)\n",
        "# # mfcc.shape\n",
        "# samples, sample_rate = librosa.load(train_changed_wav_location+'trial.wav' , sr=44100)\n",
        "# samples.shape\n",
        "# wav_roll = np.roll(samples, int(sample_rate/10))\n",
        "\n",
        "def meta_data(trans, path):\n",
        "        target = []\n",
        "        features = []\n",
        "        mode = []\n",
        "        rmse = []\n",
        "        spec_cent = []\n",
        "        spec_bw = []\n",
        "        rolloff = []\n",
        "        zcr = []\n",
        "        mfcc = []\n",
        "        rate = []\n",
        "        filenames = []\n",
        "        duration_of_recordings = []\n",
        "        for index, k in enumerate(trans):\n",
        "            if True:\n",
        "                filename = path + k + \".wav\"\n",
        "                next_file_name = path + k + \"changed.wav\"\n",
        "                if exists(filename):\n",
        "                    audio, fs = librosa.load(filename, sr=44100)\n",
        "                   \n",
        "                    chroma_stft = librosa.feature.chroma_stft(y=audio, sr=fs)\n",
        "                    rmse.append(np.mean(librosa.feature.rms(y=audio)))\n",
        "                    spec_cent.append(\n",
        "                        np.mean(librosa.feature.spectral_centroid(y=audio, sr=fs)))\n",
        "                    spec_bw.append(\n",
        "                        np.mean(librosa.feature.spectral_bandwidth(y=audio, sr=fs)))\n",
        "                    rolloff.append(\n",
        "                        np.mean(librosa.feature.spectral_rolloff(y=audio, sr=fs)))\n",
        "                    zcr.append(\n",
        "                        np.mean(librosa.feature.zero_crossing_rate(audio)))\n",
        "                    mfcc.append(np.mean(librosa.feature.mfcc(y=audio, sr=fs)))\n",
        "                    duration_of_recordings.append(float(len(audio)/fs))\n",
        "                    rate.append(fs)\n",
        "                    changed = convert_to_sterio(audio)\n",
        "                    audio = resize_audio(changed,200000)\n",
        "                   \n",
        "                    # stereo = change_channel_to_stereo(filename, next_file_name)\n",
        "                    # resized = self.resize_audio(audio,200000)\n",
        "                    split_array = str(filename).split('/')\n",
        "                    filename = '../data/train/changed_wav/' + str(split_array[len(split_array)-1])\n",
        "                    wavfile.write(os.path.join(train_changed_wav_location, str(split_array[len(split_array)-1]) ), fs, audio)\n",
        "                    filenames.append(filename)\n",
        "                    mode.append('mono')  # if stereo == 1 else 'stereo')\n",
        "                    lable = trans[k]\n",
        "                    target.append(lable)\n",
        "        # self.logger.info(f\"Meta Data Generated For {len(filenames)} Audios\")\n",
        "        return filenames, target, duration_of_recordings, mode, rmse, spec_cent, spec_bw, rolloff, zcr, mfcc, rate"
      ],
      "metadata": {
        "id": "kQ8Zn9JWPTdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loaderTrans(filename: str):\n",
        "        \"\"\"\n",
        "        # Loads the audio file and returns the audio data and sample rate\n",
        "        # param filename: The path to the txt file\n",
        "        # @return: The audio data and sample rate\n",
        "        #\n",
        "        \"\"\"\n",
        "        name_to_text = {}\n",
        "        with open(filename, encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                f.readline()\n",
        "                name=line.split(\"\\t\")[0]\n",
        "                text=line.split(\"\\t\")[1]\n",
        "                text=text.replace('\\n','')\n",
        "                name_to_text[name]=text\n",
        "                # self.logger.info(f\"Training data loaded: {name}\")\n",
        "        return name_to_text\n",
        "transcription = loaderTrans(train_txt_location)"
      ],
      "metadata": {
        "id": "pK79V0sIRWGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames, target, duration_of_recordings,mode ,rmse,spec_cent,spec_bw,rolloff,zcr,mfcc,rate = meta_data(transcription, train_wav_location)\n",
        "data = pd.DataFrame({'key': filenames, 'text': target,\n",
        "                    'duration': duration_of_recordings, 'mode': mode , 'rate': rate ,'rmse': rmse,'spec_cent' :spec_cent,'spec_bw': spec_bw,\"rolloff\" :rolloff,\"zcr\": zcr,\"mfcc\": mfcc})\n",
        "data.head()"
      ],
      "metadata": {
        "id": "P01xgU_8RdF3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}